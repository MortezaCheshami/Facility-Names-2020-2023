{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbaf0725-7a81-43ae-86bb-075f9822c056",
   "metadata": {},
   "source": [
    "### Flagging all similar data with different address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9301d12d-5e2d-43ba-a526-a610f76c0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "input_path = r\"C:\\HP - OIT - 2024\\Lefel\\Task 9 - Facility 2020-2023\\fac_sc1.2_23.xlsx\"\n",
    "output_path = r\"C:\\HP - OIT - 2024\\Lefel\\Task 9 - Facility 2020-2023\\fac_sc1.2_23_flagged.xlsx\"\n",
    "\n",
    "# Read Excel file\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# Add a row number to preserve the original order\n",
    "df['row_order'] = range(1, len(df) + 1)\n",
    "\n",
    "# Define columns to compare (excluding 'dups', 'Address', and row order)\n",
    "columns_to_check = [col for col in df.columns if col not in ['dups', 'Address', 'row_order']]\n",
    "\n",
    "# Initialize flag column\n",
    "df['address_conflict_flag'] = False\n",
    "\n",
    "# Helper function to compare values safely (handles NaN and strips strings)\n",
    "def safe_equal(val1, val2):\n",
    "    if pd.isna(val1) and pd.isna(val2):\n",
    "        return True\n",
    "    if isinstance(val1, str):\n",
    "        val1 = val1.strip()\n",
    "    if isinstance(val2, str):\n",
    "        val2 = val2.strip()\n",
    "    return val1 == val2\n",
    "\n",
    "# Compare each row with the next one\n",
    "for i in range(len(df) - 1):\n",
    "    row1 = df.iloc[i]\n",
    "    row2 = df.iloc[i + 1]\n",
    "\n",
    "    # Check if all selected columns match\n",
    "    match = all(safe_equal(row1[col], row2[col]) for col in columns_to_check)\n",
    "\n",
    "    if match:\n",
    "        addr1 = str(row1['Address']).strip() if not pd.isna(row1['Address']) else ''\n",
    "        addr2 = str(row2['Address']).strip() if not pd.isna(row2['Address']) else ''\n",
    "        if addr1 != addr2:\n",
    "            df.at[i, 'address_conflict_flag'] = True\n",
    "            df.at[i + 1, 'address_conflict_flag'] = True\n",
    "\n",
    "# Save the result to a new Excel file\n",
    "df.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1822a4c-c075-4532-81ce-1affe12df46e",
   "metadata": {},
   "source": [
    "### Removing Duplicates by True and Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c28d0c2-1a54-45c3-8c98-cf6df3839147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "input_path = r\"C:\\HP - OIT - 2024\\Lefel\\Task 9 - Facility 2020-2023\\fac_sc1.2_23_flagged.xlsx\"\n",
    "output_path = r\"C:\\HP - OIT - 2024\\Lefel\\Task 9 - Facility 2020-2023\\fac_sc1.2_23_cleaned.xlsx\"\n",
    "\n",
    "# Read Excel file\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# Define columns to use for grouping (excluding address and flag-related columns)\n",
    "group_cols = [col for col in df.columns if col not in ['Address', 'dups', 'row_order', 'address_conflict_flag']]\n",
    "\n",
    "# Initialize column to track which rows to keep\n",
    "df['keep'] = True\n",
    "\n",
    "# Focus only on rows flagged as address conflict\n",
    "conflict_df = df[df['address_conflict_flag'] == True].copy()\n",
    "\n",
    "# Create a group key based on all relevant columns (excluding address)\n",
    "conflict_df['group_key'] = conflict_df[group_cols].astype(str).agg('|'.join, axis=1)\n",
    "\n",
    "# Evaluate each group\n",
    "rows_to_keep = []\n",
    "for group_key, group in conflict_df.groupby('group_key'):\n",
    "    # Initially mark all rows in this group for removal\n",
    "    df.loc[group.index, 'keep'] = False\n",
    "\n",
    "    # Check which rows have valid (non-empty) addresses\n",
    "    group['has_address'] = group['Address'].apply(lambda x: isinstance(x, str) and x.strip() != '')\n",
    "\n",
    "    if group['has_address'].sum() == 1:\n",
    "        # If only one row has an address, keep that one\n",
    "        idx_to_keep = group[group['has_address']].index[0]\n",
    "        df.loc[idx_to_keep, 'keep'] = True\n",
    "\n",
    "    elif group['has_address'].sum() > 1:\n",
    "        # If multiple rows have addresses, keep the first one\n",
    "        idx_to_keep = group[group['has_address']].index[0]\n",
    "        df.loc[idx_to_keep, 'keep'] = True\n",
    "\n",
    "# Final filtering\n",
    "df_cleaned = df[df['keep']].drop(columns=['keep'])\n",
    "\n",
    "# Save cleaned dataset to Excel\n",
    "df_cleaned.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6bdeb3-7ff8-4f84-8796-80ebcd4a8486",
   "metadata": {},
   "source": [
    "### Sorting all duplicatied data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34791507-d2b7-41c7-ab04-4e5a991f4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths for input and output\n",
    "input_path = r\"C:\\HP - OIT - 2024\\Lefel\\Task 9 - Facility 2020-2023\\fac_sc1.2_23_cleaned.xlsx\"\n",
    "output_path = r\"C:\\HP - OIT - 2024\\Lefel\\Task 9 - Facility 2020-2023\\fac_sc1.2_23_same_facility_scope_flagged.xlsx\"\n",
    "\n",
    "# Read the cleaned dataset\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# Initialize flag column\n",
    "df['same_facility_scope_flag'] = False\n",
    "\n",
    "# Create a composite key from selected columns\n",
    "df['combo_key'] = df[['acct.facility.actual.year.clean', 'facility_scope_1', 'facility_scope_2']].astype(str).agg('|'.join, axis=1)\n",
    "\n",
    "# Find keys that appear more than once\n",
    "duplicate_keys = df['combo_key'].value_counts()\n",
    "duplicate_keys = duplicate_keys[duplicate_keys > 1].index\n",
    "\n",
    "# Flag rows that have a duplicate key\n",
    "df.loc[df['combo_key'].isin(duplicate_keys), 'same_facility_scope_flag'] = True\n",
    "\n",
    "# Drop the temporary combo_key column\n",
    "df.drop(columns=['combo_key'], inplace=True)\n",
    "\n",
    "# Save the final output with flags\n",
    "df.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339919c9-7db6-4e9d-aa40-20965d581dce",
   "metadata": {},
   "source": [
    "### Sorting with considering actual year and other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e03bada-4d00-428c-bff8-8d91e9091698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths for input and output\n",
    "input_path = r\"C:\\HP - OIT - 2024\\Lefel\\Task 9 - Facility 2020-2023\\fac_sc1.2_23_cleaned.xlsx\"\n",
    "output_path = r\"C:\\HP - OIT - 2024\\Lefel\\Task 9 - Facility 2020-2023\\fac_sc1.2_23_same_facility_scope_flagged2.xlsx\"\n",
    "\n",
    "# Read the cleaned dataset\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# Initialize the flag column\n",
    "df['same_facility_scope_flag'] = False\n",
    "\n",
    "# Create a composite key from four columns\n",
    "df['combo_key'] = df[['acct.facility.actual.year.clean', 'facility_scope_1', 'facility_scope_2', 'actual_year']].astype(str).agg('|'.join, axis=1)\n",
    "\n",
    "# Identify duplicate keys (i.e., repeated combinations)\n",
    "duplicate_keys = df['combo_key'].value_counts()\n",
    "duplicate_keys = duplicate_keys[duplicate_keys > 1].index\n",
    "\n",
    "# Flag rows with duplicate keys\n",
    "df.loc[df['combo_key'].isin(duplicate_keys), 'same_facility_scope_flag'] = True\n",
    "\n",
    "# Drop the temporary composite key\n",
    "df.drop(columns=['combo_key'], inplace=True)\n",
    "\n",
    "# Save the output with flagged rows\n",
    "df.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbef7f3-ced5-4d7b-a06d-38ce8499914c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
